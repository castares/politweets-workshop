{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librer√≠as necesarias para el Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors, FastText\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "handlers = ['sanchezcastejon', 'pablocasado_',\n",
    "     'Pablo_Iglesias_', 'Santi_ABASCAL', 'Albert_Rivera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for handler in handlers:\n",
    "    data[handler] = pd.read_csv('data/' + handler + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('', \"data/*.csv\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estos 3 minutos de @EspejoPublico a @PedroRuiz...</td>\n",
       "      <td>Tue Dec 03 18:10:08 +0000 2019</td>\n",
       "      <td>1.201927e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üòÇüòÇüòÇ https://t.co/C2dJ2TjGwo</td>\n",
       "      <td>Sat Nov 30 17:39:22 +0000 2019</td>\n",
       "      <td>1.200832e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lo advertimos antes del 10N. \\nEl PSOE de S√°nc...</td>\n",
       "      <td>Tue Nov 26 11:17:34 +0000 2019</td>\n",
       "      <td>1.199286e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>¬°Sois muy grandes, campeones! Hab√©is vuelto a ...</td>\n",
       "      <td>Sun Nov 24 20:37:25 +0000 2019</td>\n",
       "      <td>1.198702e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dec√≠a el presidente Kennedy que lo inteligente...</td>\n",
       "      <td>Sun Nov 24 10:43:17 +0000 2019</td>\n",
       "      <td>1.198553e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  Estos 3 minutos de @EspejoPublico a @PedroRuiz...   \n",
       "1                        üòÇüòÇüòÇ https://t.co/C2dJ2TjGwo   \n",
       "2  Lo advertimos antes del 10N. \\nEl PSOE de S√°nc...   \n",
       "3  ¬°Sois muy grandes, campeones! Hab√©is vuelto a ...   \n",
       "4  Dec√≠a el presidente Kennedy que lo inteligente...   \n",
       "\n",
       "                       created_at            id  \n",
       "0  Tue Dec 03 18:10:08 +0000 2019  1.201927e+18  \n",
       "1  Sat Nov 30 17:39:22 +0000 2019  1.200832e+18  \n",
       "2  Tue Nov 26 11:17:34 +0000 2019  1.199286e+18  \n",
       "3  Sun Nov 24 20:37:25 +0000 2019  1.198702e+18  \n",
       "4  Sun Nov 24 10:43:17 +0000 2019  1.198553e+18  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec basic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec input format: list of tokens in documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(df['tweet'])\n",
    "dataset = [sent.split(' ') for sent in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "        dataset,\n",
    "        size=2,\n",
    "        sg=1, #Skip-Gram\n",
    "        min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.5368118 , -0.86686504], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('econom√≠a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://t.co/CMCVS5VoaI', 1.0),\n",
       " ('bien', 1.0),\n",
       " ('presentadas', 1.0),\n",
       " ('https://t.co/EbNzjF4E4E', 1.0),\n",
       " ('https://t.co/wu0KiBW5Sr', 1.0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"econom√≠a\"]\n",
    "model.wv.most_similar (positive=w1,topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lacra.\\nMi', 1.0000001192092896),\n",
       " ('https://t.co/ntZTP3bkUH', 1.0),\n",
       " ('populistas', 1.0),\n",
       " ('@PPopular', 1.0),\n",
       " ('https://t.co/r3DV4mOlha', 1.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"educaci√≥n\"]\n",
    "model.wv.most_similar (positive=w1,topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(size=2, min_count=0)  # instantiate\n",
    "model.build_vocab(sentences=dataset)\n",
    "model.train(sentences=dataset, total_examples=len(dataset), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.99747   ,  0.05966096], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('econom√≠a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Inmoral.', 1.0),\n",
       " ('historia!!', 1.0),\n",
       " ('#transici√≥necol√≥gica,', 1.0),\n",
       " ('unanimidad', 1.0),\n",
       " ('üèÜCampe√≥n', 1.0)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"econom√≠a\"]\n",
    "model.wv.most_similar (positive=w1,topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import spacy\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ermartin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estos 3 minutos de @EspejoPublico a @PedroRuiz_Photo contando las historias y los sentimientos que hay detr√°s de cada foto son una joya. No os lo perd√°is. ¬°Gracias, Pete! Yo tambi√©n he perdido a un fot√≥grafo pero he ganado un gran amigo üòâüì∏ https://t.co/OU9eH1NKEw'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = list(df['tweet'])\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'estos 3 minutos de @espejopublico a @pedroruiz_photo contando las historias y los sentimientos que hay detr√°s de cada foto son una joya. no os lo perd√°is. ¬°gracias, pete! yo tambi√©n he perdido a un fot√≥grafo pero he ganado un gran amigo üòâüì∏ https://t.co/ou9eh1nkew'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lwr = []\n",
    "for sent in dataset:\n",
    "    data_lwr.append(sent.lower())\n",
    "data_lwr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'estos 3 minutos de @espejopublico a @pedroruiz_photo contando las historias y los sentimientos que hay detras de cada foto son una joya. no os lo perdais. gracias, pete! yo tambien he perdido a un fotografo pero he ganado un gran amigo  https://t.co/ou9eh1nkew'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_std = []\n",
    "for sent in data_lwr:\n",
    "    data_std.append(unicodedata.normalize('NFKD', sent).encode('ASCII', 'ignore').decode('utf-8'))\n",
    "data_std[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estos',\n",
       " '3',\n",
       " 'minutos',\n",
       " 'de',\n",
       " '@',\n",
       " 'espejopublico',\n",
       " 'a',\n",
       " '@',\n",
       " 'pedroruiz_photo',\n",
       " 'contando',\n",
       " 'las',\n",
       " 'historias',\n",
       " 'y',\n",
       " 'los',\n",
       " 'sentimientos',\n",
       " 'que',\n",
       " 'hay',\n",
       " 'detras',\n",
       " 'de',\n",
       " 'cada',\n",
       " 'foto',\n",
       " 'son',\n",
       " 'una',\n",
       " 'joya',\n",
       " '.',\n",
       " 'no',\n",
       " 'os',\n",
       " 'lo',\n",
       " 'perdais',\n",
       " '.',\n",
       " 'gracias',\n",
       " ',',\n",
       " 'pete',\n",
       " '!',\n",
       " 'yo',\n",
       " 'tambien',\n",
       " 'he',\n",
       " 'perdido',\n",
       " 'a',\n",
       " 'un',\n",
       " 'fotografo',\n",
       " 'pero',\n",
       " 'he',\n",
       " 'ganado',\n",
       " 'un',\n",
       " 'gran',\n",
       " 'amigo',\n",
       " 'https',\n",
       " '://',\n",
       " 't',\n",
       " '.',\n",
       " 'co',\n",
       " '/',\n",
       " 'ou9eh1nkew']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tkn = []\n",
    "for sent in data_std:\n",
    "    data_tkn.append(wordpunct_tokenize(sent))\n",
    "data_tkn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['estos',\n",
       " 'minutos',\n",
       " 'de',\n",
       " 'espejopublico',\n",
       " 'a',\n",
       " 'contando',\n",
       " 'las',\n",
       " 'historias',\n",
       " 'y',\n",
       " 'los',\n",
       " 'sentimientos',\n",
       " 'que',\n",
       " 'hay',\n",
       " 'detras',\n",
       " 'de',\n",
       " 'cada',\n",
       " 'foto',\n",
       " 'son',\n",
       " 'una',\n",
       " 'joya',\n",
       " 'no',\n",
       " 'os',\n",
       " 'lo',\n",
       " 'perdais',\n",
       " 'gracias',\n",
       " 'pete',\n",
       " 'yo',\n",
       " 'tambien',\n",
       " 'he',\n",
       " 'perdido',\n",
       " 'a',\n",
       " 'un',\n",
       " 'fotografo',\n",
       " 'pero',\n",
       " 'he',\n",
       " 'ganado',\n",
       " 'un',\n",
       " 'gran',\n",
       " 'amigo',\n",
       " 'https',\n",
       " 't',\n",
       " 'co']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pnkt = []\n",
    "for sent in data_tkn:\n",
    "    data_pnkt.append([word for word in sent if word.isalpha()])\n",
    "data_pnkt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = stopwords.words('spanish')\n",
    "sw[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minutos',\n",
       " 'espejopublico',\n",
       " 'contando',\n",
       " 'historias',\n",
       " 'sentimientos',\n",
       " 'detras',\n",
       " 'cada',\n",
       " 'foto',\n",
       " 'joya',\n",
       " 'perdais',\n",
       " 'gracias',\n",
       " 'pete',\n",
       " 'tambien',\n",
       " 'perdido',\n",
       " 'fotografo',\n",
       " 'ganado',\n",
       " 'gran',\n",
       " 'amigo',\n",
       " 'https',\n",
       " 't',\n",
       " 'co']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stp = []\n",
    "for sent in data_pnkt:\n",
    "    data_stp.append([word for word in sent if not word in sw])\n",
    "data_stp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minuto',\n",
       " 'espejopublico',\n",
       " 'contar',\n",
       " 'historia',\n",
       " 'sentimiento',\n",
       " 'detras',\n",
       " 'cada',\n",
       " 'foto',\n",
       " 'joya',\n",
       " 'perdais',\n",
       " 'gracia',\n",
       " 'petar',\n",
       " 'tambien',\n",
       " 'perder',\n",
       " 'fotografo',\n",
       " 'ganar',\n",
       " 'gran',\n",
       " 'amigar',\n",
       " 'https',\n",
       " 't',\n",
       " 'co']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm = spacy.blank('es')\n",
    "data_lemm = []\n",
    "for sent in data_stp:\n",
    "    data_lemm.append([tokens.lemma_ for tokens in lemm(' '.join(word for word in sent))])\n",
    "data_lemm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['minut',\n",
       " 'espejopubl',\n",
       " 'cont',\n",
       " 'histori',\n",
       " 'sentimient',\n",
       " 'detr',\n",
       " 'cad',\n",
       " 'fot',\n",
       " 'joy',\n",
       " 'perdais',\n",
       " 'graci',\n",
       " 'pet',\n",
       " 'tambi',\n",
       " 'perd',\n",
       " 'fotograf',\n",
       " 'gan',\n",
       " 'gran',\n",
       " 'amig',\n",
       " 'https',\n",
       " 't',\n",
       " 'co']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('spanish')\n",
    "data_stem = []\n",
    "for sent in data_stp:\n",
    "    data_stem.append([stemmer.stem(word) for word in sent])\n",
    "data_stem[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec + Preprocessing + Hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "        data_lemm,\n",
    "        size=300,\n",
    "        sg=0, #Skip-Gram\n",
    "        min_count=0,\n",
    "        iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22485635,  1.9060785 , -0.7529961 , -0.73270696, -1.337491  ,\n",
       "        1.2403338 ,  0.24137034,  0.7897106 ,  0.83259606, -0.7240762 ,\n",
       "       -0.5598111 ,  2.3932803 ,  0.6885952 , -1.029048  ,  0.20227851,\n",
       "        0.32435822,  0.38391966, -0.9660038 ,  0.10311033, -0.08994564,\n",
       "        0.8718674 , -0.60313493,  0.5347903 , -0.07227661,  0.60987353,\n",
       "        0.0050941 , -0.6552838 , -0.89252836,  0.26420036, -0.63748   ,\n",
       "       -1.3078681 , -0.25982788, -0.08865281, -1.6938784 , -0.28293437,\n",
       "        1.3580698 , -0.0226552 , -0.476426  ,  0.8719193 ,  0.41868076,\n",
       "        0.20205292,  0.9243562 , -0.94761443, -1.3627263 , -0.00395201,\n",
       "        0.5220138 ,  1.0406401 ,  0.47904032, -0.19518796,  0.9000996 ,\n",
       "       -0.63928133,  0.09340114, -0.56967634,  0.12233819, -0.6296528 ,\n",
       "        0.07959235,  0.9433808 ,  0.87400055,  0.455717  , -0.2123958 ,\n",
       "       -0.8102293 , -0.35573125,  0.74859947, -0.7109837 ,  0.35554492,\n",
       "       -0.5320631 ,  0.2712223 ,  0.5050528 , -1.2983769 ,  0.63821673,\n",
       "        0.8047391 , -0.9006767 ,  1.1221026 , -1.3394164 , -0.8341529 ,\n",
       "        0.06565367,  0.9392759 ,  0.08111843, -0.49367163,  0.5612565 ,\n",
       "       -1.8152335 ,  0.08577882, -0.5276454 , -0.4444254 ,  0.302221  ,\n",
       "        0.44936156, -1.2061875 , -0.18150583, -0.31957924,  0.1710553 ,\n",
       "        0.59657925,  0.7082122 ,  0.46216804, -0.9407017 , -0.3698432 ,\n",
       "       -0.16613133, -1.1663237 ,  0.39414334,  1.3172607 ,  1.1492009 ,\n",
       "        0.65548694,  0.10151667, -1.6028553 , -1.3331076 , -0.7873248 ,\n",
       "        0.5269801 , -0.14861242, -0.8320807 ,  0.0832309 , -1.0763792 ,\n",
       "        0.63043106, -0.91537637,  0.13361494,  0.7990354 , -0.70368177,\n",
       "        0.71402913, -0.9106596 ,  0.31862813,  0.01024338, -0.10628784,\n",
       "       -0.29972023, -0.31860113,  1.0844376 , -1.055059  ,  1.3222625 ,\n",
       "       -1.8986169 ,  0.51219374, -1.0530593 , -1.370522  , -0.7651774 ,\n",
       "       -0.04978121,  0.43213254, -0.57653445, -1.8612021 ,  0.8347756 ,\n",
       "        0.51449347,  0.14049353, -0.5270041 , -0.7604224 ,  0.13026287,\n",
       "        0.30553925,  0.4385865 ,  0.54040563,  0.48028493, -0.7995518 ,\n",
       "       -1.2019967 , -0.14224231,  0.29621834, -0.184523  , -0.27854335,\n",
       "       -0.88814193, -0.38311592, -0.8163827 ,  1.1450787 ,  0.57470816,\n",
       "        1.4177421 , -0.24148229, -1.0655974 , -0.05447215, -1.6074983 ,\n",
       "       -1.327688  ,  1.6688405 , -1.7392986 , -0.77512413,  1.9849439 ,\n",
       "        0.5737647 ,  0.15415247, -0.26582325,  0.7064861 ,  0.82163244,\n",
       "       -0.1692676 , -0.21203703,  0.45223498, -0.65084875,  0.88860786,\n",
       "       -0.57865447,  0.1503387 ,  0.5751641 , -0.7908542 , -0.46867365,\n",
       "        1.0078243 , -1.3437787 ,  0.10642706,  0.09749655, -0.86382216,\n",
       "        0.7012154 , -0.5681405 ,  0.98019326,  0.910666  ,  1.7251517 ,\n",
       "        0.29979172, -0.62160045,  0.4456434 ,  0.19693618,  0.6919194 ,\n",
       "        0.76805526,  0.8185124 , -1.3365759 , -0.27391002,  0.00324661,\n",
       "       -0.25970882, -1.6164325 , -0.25486264, -0.7336664 ,  1.0572646 ,\n",
       "        1.0476192 ,  0.30962443, -1.5236257 ,  0.3609896 , -0.15885039,\n",
       "       -0.73269904,  0.12212261,  1.3222898 ,  0.42278346,  0.15122499,\n",
       "        2.454674  , -0.32409313, -0.42635164, -0.06549565, -0.4153864 ,\n",
       "       -0.35906902, -0.50495553,  0.34934917, -0.26689276, -1.1195726 ,\n",
       "       -0.09193806,  0.01858144,  0.5665414 ,  0.4036431 ,  0.179537  ,\n",
       "        0.10144508,  0.4917496 ,  0.7459238 ,  2.0470085 ,  1.3429288 ,\n",
       "        0.483773  ,  0.9171367 ,  0.53389907, -0.04078066, -0.5294093 ,\n",
       "       -0.05025252, -0.3099238 ,  1.3919591 , -0.19270937,  0.10486525,\n",
       "       -1.6190883 , -0.9120062 , -0.01362658, -0.48068175, -0.8765129 ,\n",
       "        0.10320564, -1.5715748 , -0.7317867 , -0.03250958, -0.3287201 ,\n",
       "        0.78098166, -0.33544162,  1.1096889 , -0.2271763 ,  0.29225907,\n",
       "       -0.54773754, -0.8742613 ,  0.63980234,  0.3751236 ,  0.24022187,\n",
       "       -1.2597522 ,  0.62940186,  0.8695395 , -0.18242097, -1.256498  ,\n",
       "        1.0132642 , -1.0273168 ,  1.093208  ,  0.00706957,  0.51773566,\n",
       "        1.0012282 , -0.0233711 ,  0.34467295,  0.3381787 ,  0.57676864,\n",
       "       -0.13822663,  0.28057027, -0.7971938 , -0.77334744, -0.40984663,\n",
       "       -2.0503569 ,  0.23397054, -0.1855999 , -0.68208003,  1.6322155 ,\n",
       "        1.4663804 , -0.13952313,  1.0831553 ,  0.58009046,  1.0761218 ,\n",
       "        0.34630063, -0.48056152, -0.36804703,  1.845702  , -0.5387777 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('economia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('economico', 0.6003372073173523),\n",
       " ('competitividad', 0.5598915815353394),\n",
       " ('pib', 0.5515145063400269),\n",
       " ('enfriamiento', 0.551472544670105),\n",
       " ('ralentizacion', 0.543662428855896)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"economia\"]\n",
    "model.wv.most_similar(positive=w1,topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained = KeyedVectors.load_word2vec_format('models/wiki.es.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab([list(model_pretrained.vocab.keys())], update=True)\n",
    "model.intersect_word2vec_format('models/wiki.es.vec', lockf=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oeconomia', 0.8983333110809326),\n",
       " ('economias', 0.8931393623352051),\n",
       " ('/economia', 0.8916008472442627),\n",
       " ('//economia', 0.8205404877662659),\n",
       " ('macroeconomia', 0.8028700947761536)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"economia\"]\n",
    "model.wv.most_similar(positive=w1,topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oeconomia', 0.8983333110809326),\n",
       " ('economias', 0.8931393623352051),\n",
       " ('/economia', 0.8916008472442627),\n",
       " ('//economia', 0.8205404877662659),\n",
       " ('macroeconomia', 0.8028700947761536),\n",
       " ('economi', 0.797034740447998),\n",
       " ('microeconomia', 0.7822957634925842),\n",
       " ('economico', 0.7618166208267212),\n",
       " ('economica', 0.7474629282951355),\n",
       " ('econom', 0.7408113479614258),\n",
       " ('ekonomia', 0.7335286140441895),\n",
       " ('americaeconomia', 0.7213191390037537),\n",
       " ('economice', 0.7168940305709839),\n",
       " ('/economia/', 0.7121700048446655),\n",
       " ('economicƒÉ', 0.7101243138313293)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"economia\"]\n",
    "model.wv.most_similar(positive=w1,topn=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (politweets)",
   "language": "python",
   "name": "politweets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "name": "NLP",
  "notebookId": 1051303103013690
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
